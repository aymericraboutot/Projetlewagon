# -*- coding: utf-8 -*-
"""Projet - CasNat - VF

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sUy7niV60PGbhDpjW-HgqegOx_nCqsGA

# **Import des librairies**

---
"""

import pandas as pd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime as dt

!pip install pycountry babel
import pycountry
from babel import Locale

"""# **Import de la base de données principale et première exploration**

---





"""

# import de la liste des catastrophes répertoriées par EM-DAT
df = pd.read_excel('global_disaster_1980-2025.xlsx')

df.head()

df.shape

df.info()

"""# **Nettoyage de la base de données principale**

---





"""

# Modification du nom des colonnes pour remplacer les espaces et caractères spéciaux par '_'

df.columns = df.columns.str.replace(r'\s*\(.*\)', '', regex=True)
df.columns = df.columns.str.lower().str.replace(' ', '_')
df.columns = df.columns.str.replace(',', '')
df.columns = df.columns.str.strip()  # enlève les espaces au début/fin
df.columns = df.columns.str.replace('[,._ ]+$', '', regex=True)

# Suppression des colonnes inutiles pour le projet :
    # 'entry_date', 'last_update', 'end_year'  : dates non utiles
    # 'country' : remplacé par la colonne pays
    # 'classification_key' : ce n'est pas une clé et ne pourrait servir qu'en filtre qui est inadapté à notre projet
    # autres colonnes : manque de données ou données non pertinentes pour notre projet

df = df.drop([
    "entry_date",
    "last_update",
    "admin_units",
    "cpi",
    "reconstruction_costs",
    "reconstruction_costs_adjusted",
    "external_ids",
    "insured_damage",
    "insured_damage_adjusted",
    "total_damage",
    "country",
    "classification_key",
    "origin",
    "associated_types",
    "ofda/bha_response",
    "appeal",
    "declaration",
    "aid_contribution",
    "latitude",
    "longitude",
    "river_basin",
    ], axis=1)

# Exclusion des années antérieures à 1990 car les données ne sont pas fiables avant cette date d'après l'éditeur du dataset
# Exclusion de l'année 2025 car c'est l'année en cours

# Sélection des données comprises entre 1990 et 2024 inclus :
df = df[(df['start_year'] >= 1990)&(df['start_year'] < 2025)]

"""## *Modification des données géographiques*"""

# traduction des pays en français dans une nouvelle colonne 'pays' d'après l'iso à 3 lettres

    # Fonction de conversion ISO3 -> Nom français
def iso3_to_country_name_fr(iso3_code: str) -> str:
    """
    Convertit un code ISO3 (ex: 'FRA') en nom de pays en français.
    Retourne None si le code est invalide ou inconnu.
    """
    if not isinstance(iso3_code, str) or len(iso3_code) != 3:
        return None
    try:
        country = pycountry.countries.get(alpha_3=iso3_code.upper())
        if not country:
            return None
        locale_fr = Locale('fr')
        country_name_fr = locale_fr.territories.get(country.alpha_2)
        return country_name_fr or country.name
    except Exception:
        return None
    # Création de la colonne "pays"
df["pays"] = df["iso"].apply(iso3_to_country_name_fr)

# Réassignation des anciens isos qui ne sont plus utilisés vers le pays qui nous parait le plus cohérent aujourd'hui :
    # SUN : URSS --> Russie
    # YUG : Yougoslavie --> Serbie
    # SCG : Serbie Monténégro --> Serbie
    # ANT : Antilles Néherlandaises --> Pays-Bas
    # AZO : Açores --> Portugal
    # SPI : Canaries --> Espagne

# Dictionnaire pour les réassignations :
remplacements = {
    "SUN": "Russie",
    "YUG": "Serbie",
    "SCG": "Serbie",
    "ANT": "Pays-Bas",
    "AZO": "Portugal",
    "SPI": "Espagne"
}

# Mise à jour de la colonne 'pays' uniquement si elle est vide
df.loc[df["iso"].isin(remplacements.keys()) & df["pays"].isna(), "pays"] = \
    df["iso"].map(remplacements)

# Nettoyage dela colonne 'location' (finalement non exploité dans notre projet)

df['location'] = np.where(df['location'] == 'Dhamar province', 'Dhamar',
  np.where(df['location'] == 'Jabal Bahr, Bani Zahir villages (Al-Udayn district, Hazm Al-Udein district, Ebb province)', 'Ibb',
  np.where(df['location'] == 'Abyan', 'Abyan',
  np.where(df['location'] == 'Nationwide', 'Yemen',
  np.where(df['location'] == 'Saiyoon district (Central and Eastern regions)', 'Hadramaut',
  np.where(df['location'] == 'Socotra IsL.', 'Socotra',
  np.where(df['location'] == 'Lahej, Abyan, Aden Governorates', 'Lahj',
  np.where(df['location'] == 'Shabwa, Mareb, Hadhramout, Aljawf, El Jouf, Abin Governorates', 'Shabwa',
  np.where(df['location'] == 'Hudayda, Taiz regions', 'Al Hudaydah',
  np.where(df['location'] == 'Tihama Valley in Al Hodeida Governate, Al-Zahara and Al-Luhyah districts', 'Al Hudaydah',
  np.where(df['location'] == 'Siham valley Red Sea port Hodeida Ibb Abin Marib Sanaa Lahaj (West Yemen)', 'Al Hudaydah',
  np.where(df['location'] == 'Socotra Archipelago', 'Socotra',
  np.where(df['location'] == "Amran, Hadramaut, Sa'ada, Al Hudaydah provinces", 'Amran',
  np.where(df['location'] == 'Hadramaut province', 'Hadramaut',
  np.where(df['location'] == 'As Salafiyah district (Raymah province)', 'Raymah',
  np.where(df['location'] == 'Raymah province', 'Raymah',
  np.where(df['location'] == 'Taizz, Al Hudaydah, Hadramaut provinces', 'Taiz',
  np.where(df['location'] == 'Hajjah, Taizz provinces', 'Hajjah',
  np.where(df['location'] == "Sana'a, Al Hudaydah provinces", 'Sanaa',
  np.where(df['location'] == "Al Hudaydah, Al Jawf, Al Mahwit, Amran, Hajjah, Sa'ada, Taizz provinces", 'Al Hudaydah',
  np.where(df['location'] == "Ma'arbar city (Jahran district, Dhamar province)", 'Dhamar',
  np.where(df['location'] == "Dhamar, Al Hudaydah, Sana'a, Taizz, Sa'ada provinces", 'Dhamar',
  np.where(df['location'] == 'Rayma, Dhamar provinces', 'Raymah',
  np.where(df['location'] == 'Hadramaut, Ibb provinces', 'Hadramaut',
  np.where(df['location'] == 'Sana’a province', 'Sanaa',
  np.where(df['location'] == 'Tarim, Sah, Shibam, Al Qatn, Wadi Al Ayn districts (Hadramaut province), Al Maharah, Taizz, Lahj, Al Mahwit provinces', 'Hadramaut',
  np.where(df['location'] == "Sana'a province", 'Sanaa',
  np.where(df['location'] == 'Al Mashannah district (Ibb province), Dhamar, Sana\'a provinces', 'Ibb',
  np.where(df['location'] == 'Taizz, Dhamar, Al Mahwit, Sana\'a, Ibb, Hajjah, Al Hudaydah, Shabwah, Abyan provinces', 'Taiz',
  np.where(df['location'] == 'Al Hudaydah, Amran, Hajjah, Sana\'a, Hajjah, Al Mahwit, Aden, Marib provinces', 'Al Hudaydah',
  np.where(df['location'] == 'Taëz, Lahj provinces, Portions of Jibla (south of Ibb), Taizz city, Ibb city', 'Taiz',
  np.where(df['location'] == 'Marib, Sa’ada, Aden, Shabwa, Lahj, Taizz, Hadramaut, Ibb, Al Bayda, Al Jawf, Hajjah, Dhamar, Rayma, Hajjah governorates.', 'Marib',
  np.where(df['location'] == 'Sanaa', 'Sanaa',
  np.where(df['location'] == 'Al Mahwit Governorate, Ibb Governorate', 'Al Mahwit',
  np.where(df['location'] == 'Lahj, Aden, Abyan, Taizz, Al Dale’e, Al Mahrah and Hadramaut governorates', 'Lahj',
  np.where(df['location'] == 'Aden, Lahj, Taiz, Ad Dali’, Abyan, Hadramawt governorates', 'Aden',
  np.where(df['location'] == 'Hadhramaut, Shabwa, Al Mahrah', 'Hadramaut',
  np.where(df['location'] == 'Sanaa, Ibb, Shabwa, Hodeida, Aden, Abyan, Al Dhale’e, Lahj, Hadramaut, Ma’rib and Ta’iz governorates', 'Sanaa',
  np.where(df['location'] == 'Dhamar, Amran, Al Mahwit, Marib, Ibb, Sana’a, Hajjah, Al Hodeidah, Al Jawf, Al Bayda, Al Dhale, Raymah, Hadramout , Lahj, Shabwah, Al Mahrah, Socotra governorates.', 'Dhamar',
  np.where(df['location'] == 'Ad Dali’, Al Hodeidah, Hadramawt, Hajjah and Ta’iz governorate', 'Al Dhale',
  np.where(df['location'] == 'Marib, Al Mahwit, Taiz, Ibb, Hadramawt, Al Bayda, Amran, Sadaa, Dhamar Al Hodeida, Sana\'a Hajjah, Al Mahra governorates (Sanna)', 'Marib',
  np.where(df['location'] == 'Hajjah, Al Jawf, Saada, and Ma’rib Governorates', 'Hajjah',
  np.where(df['location'] == 'Hajjah, Marib, Hodeidah, Al Bayda, Al Jawf, Sana\'a, Amran, Sa’ada, Ibb, Taiz, Dhamar, Shabwa and Al Mahwit governorates', 'Hajjah',
  np.where(df['location'] == 'Abyan, Taiz, Al-Jawf, Hadramout, Shabwa, Sa\'ada, Mareb, Al-Mahara, Al-Dhale\'', 'Abyan',
  np.where(df['location'] == 'Maqbanah district (Taez governorate), Sadaa provinces; Al Hudaydah, Al Hajjah, Ma\'rib governorates', 'Taiz',
  np.where(df['location'] == 'Al-Mahwit governorate', 'Al Mahwit',
  np.where(df['location'] == 'byan, Ad Dali’, Al Bayada, Al Hodeidah, Al Jawf, Al Maharah, Al Mahwit, Amran, Dhamar, Hadramawt, Haijah, Ibb, Lahj, Ma’rib, Raymah, Sa’dah, Sana’a, Sana’s City, Shabwah and Ta’iz governorates', 'Abyan',
  np.where(df['location'] == 'Ibb, Abyan, Amanat Al-Asima, Al-Bayda, Taiz, Al-Jawf, Hajja, Al-Hodeida, Hadramout, Dhamar, Shabwa, Sa\'ada, Sana\'a, Aden, Lahj, Mareb, Al-Mahwit, Al-Mahara, Amran, Al-Dhale\', Rayma', 'Ibb',
  np.where(df['location'] == 'Al-Dhafir village (Bani Matar District, Sana\'a Governorate)', 'Sanaa',
  np.where(df['location'] == 'Modawar village (Al Mahwait district, Al Mahwit province)', 'Al Mahwit',
  np.where(df['location'] == 'Al-Lassbah village (Al-Shamayteen mountain region, Taez province)', 'Taiz',
  np.where(df['location'] == 'Sa\'ada province', 'Saada',
  np.where(df['location'] == 'Aden province', 'Aden',
  np.where(df['location'] == 'Abyan, Hadramaut, Shabwah provinces', 'Abyan',
  np.where(df['location'] == 'Hidaybu, Qulensya Wa Abd Al Kuri districts (Hadramaut province), Aden province', 'Hadramaut',
  np.where(df['location'] == 'Al Maharah governorate', 'Al Mahrah',
  np.where(df['location'] == 'Hadramout, Shabwa, Al-Mahara, Al Mahrah, Socotra Governorates', 'Hadramaut',
  np.where(df['location'] == 'Jabal Al-Tayr island (Alluheyah district, Al Hudaydah province)', 'Al Hudaydah',
df['location']))))))))))))))))))))))))))))))))))))))))))))))))))))))))))

# Séparation du continent 'Amérique' en  'Amérique du Sud' et 'Amérique du Nord' pour une meilleure représentation sur les cartes avec Looker

df['region'] = np.where(df['subregion']== 'Latin America and the Caribbean', 'South America', np.where(df['subregion']== 'Northern America','North America',df['region']))
df['region'].unique()

"""## *Traduction anglais - français*"""

# traduction des titres de colonne

df.rename(columns={
    'disno' : 'numero_de_catastrophe',
    'historic' : 'historique',
    'event_name' : 'nom_evenement',
    'subregion' : 'sous_continent',
    'region' : 'continent',
    'disaster_group' : 'nature_de_la_catastrophe',
    'disaster_subgroup' : 'groupe_de_catastrophe',
    'disaster_type' : 'type_de_catastrophe',
    'total_deaths' : 'nb_morts',
    'no._injured': 'nb_blesses',
    'no._affected' : 'nb_affectes',
    'no._homeless' : 'nb_sans_abris',
    'nb_injured_or_dead' : 'nb_blesses_ou_morts',
    'year' : 'annee',
    'month' : 'mois',
    'day' : 'jour',
    'date_date' : 'date'
    }, inplace=True)

# Traduction des données de la colonne 'groupe_de_catrastrophe'

remplacements = {
    "Hydrological": "Hydrologique",
    "Meteorological": "Météorologique",
    'Geophysique' : 'Géophysique',
    'Climatological' : 'Climatologique',
    'Extra-terrestrial' : 'Extraterrestre'
}
df["groupe_de_catastrophe"] = df["groupe_de_catastrophe"].replace(remplacements)

# Traduction des données de la colonne 'type_de_catrastrophe'

remplacements = {
    'Flood' : 'Inondation',
    'Storm' : 'Tempête',
    'Mass movement (wet)' : 'Mouvement de masse humide',
    'Earthquake' : 'Seisme',
    'Volcanic activity' : 'Activité volcanique',
    'Mass movement (dry)' : 'Mouvement de masse sec',
    'Extreme temperature' : 'Température extrême',
    'Wildfire' : 'Feu de forêt',
    'Drought' : 'Sécheresse',
    'Impact' : 'Impact',
    'Glacial lake outburst flood' : 'Inondation par rupture de lac glaciaire'
}
df["type_de_catastrophe"] = df["type_de_catastrophe"].replace(remplacements)

# Traduction des données de la colonne 'sous-continent'

remplacements = {
    'Southern Asia' : 'Asie du sud',
    'Northern Africa' : 'Afrique du nord',
    'Polynesia' : 'Polynésie',
    'Western Europe' : 'Europe de l ouest',
    'South-eastern Asia': 'Asie du sud est',
    'Latin America and the Caribbean' : 'Amérique latine et Caraïbes',
    'Sub-Saharan Africa' : 'Afrique subsaharienne',
    'Eastern Europe' : 'Europe de l est',
    'Western Asia' : 'Asie de l ouest',
    'Eastern Asia' : 'Asie de l est',
    'Northern America' : 'Amérique du nord',
    'Australia and New Zealand' : 'Australie et Nouvelle_Zélande',
    'Southern Europe' : 'Europe du sud',
    'Melanesia' : 'Mélanesie',
    'Northern Europe' : 'Europe du nord',
    'Micronesia' : 'Micronésie'
}
df["sous_continent"] = df["sous_continent"].replace(remplacements)

# Traduction des données de la colonne 'continent'

remplacements = {
    'Asia' : 'Asie',
    'Africa' : 'Afrique',
    'Oceania' : 'Océanie',
    ' North America' : 'Amérique du Nord',
    'South America' : 'Amérique du Sud'
}
df["continent"] = df["continent"].replace(remplacements)

"""# **Création de nouvelles variables**"""

# La colonne 'numero_de_catastrophe' est une clé unique composée de l'année, du numéro d'évenement et du code iso à 3 lettres du pays
    # exemple : 1990-0001-LKA
# Quand une catastrophe se produit sur plusieurs pays en même temps, elle est répartie sur chaque pays et autant de lignes dans le dataset
    # exemple fictif : 1990-0001-LKA et 1990-001-FRA
# Afin de pouvoir calculer le nombre exact de catastrophe, il nous faut créer une nouvelle colonne sans l'iso du pays et y appliquer un compte de valeur unique :

# Création d'une colonne 'disaster_id' qui reprend le numéro de catastrophe sans le '-' et le code iso à 3 lettres du pays
    # Exemple : 1990-0001-LKA --> 1990-0001
    #           1990-0001-FRA --> 1990-0001

df['disaster_id'] = df['numero_de_catastrophe'].str[:-4]

# Création d'une colonne 'nb_blesses_ou_morts' qui additionne le nombre de blessés et le nombre de morts :

df['nb_blesses'].fillna(0, inplace = True)
df['nb_morts'].fillna(0, inplace = True)
df['nb_blesses_ou_morts'] = df['nb_morts'] + df['nb_blesses']
df[['numero_de_catastrophe','nb_blesses','nb_morts','nb_blesses_ou_morts']].head()

# Création d'une colonne 'duration' qui montre la durée de la catastrophe

    # 1 - Création d'une colonne 'date_date_début' à partir de ........

from datetime import date
import datetime as dt

df['start_year'] = df['start_year'].astype(int,errors='ignore')
df['start_month'] = df['start_month'].astype(int,errors='ignore')
df['start_day'] = df['start_day'].fillna(1).astype(int,errors='ignore')
df['start_date'] = pd.to_datetime(dict(year=df['start_year'], month=df['start_month'], day=df['start_day']))
df = df.drop(['start_month', 'start_day'], axis=1)

    # 2 - Création d'une colonne 'date_date_fin'

df['end_year'] = df['end_year'].astype(int,errors='ignore')
df['end_month'] = df['end_month'].astype(int,errors='ignore')
df['end_day'] = df['end_day'].fillna(1).astype(int,errors='ignore')
df['end_date'] = pd.to_datetime(dict(year=df['end_year'], month=df['end_month'], day=df['end_day']))
df['end_date']
df = df.drop(['end_month', 'end_day'], axis=1)

    # 3 - Création de la colonne 'duration'

df['duration'] = (df['end_date'] - df['start_date']) / np.timedelta64(1, 'D')

"""# **Enrichissement avec les bases de données secondaires**

## *Import et modification des bases de données secondaires*
"""

# Import des bases de données secondaires

    # PIB par habitant en dollars constant par pays et par an
df_pib = pd.read_csv("PIB_hab_constant_-_API_NY.GDP.PCAP.KD_DS2_fr_csv_v2_23940.csv")

    # Population par pays et par an
df_pop = pd.read_csv("Population_-_API_SP.POP.TOTL_DS2_fr_csv_v2_8983.csv")

    # Taux d'urbanisation par pays et par an
df_urbanisation = pd.read_csv("Urban_population_-_WB_WDI_SP_URB_TOTL_IN_ZS_WIDEF.csv")

    # IDH par pays et par an (Indice de Développement Humain)
df_IDH = pd.read_csv("human-development-index_-_human-development-index_(1) (1).csv")

    # liste des pays en guerre en 2024
df_conflit = pd.read_excel("Pays en guerre.xlsx")

# PIB par habitant

    # Fusionner les colonnes années en une seule colonne 'Année'
df_pib = df_pib.melt(
    id_vars=["Country Name", "ISO"],
    var_name="Annee",
    value_name="PIB_Habitant"
)

    # Convertir l'année en nombre
df_pib["Annee"] = pd.to_numeric(df_pib["Annee"], errors="coerce")

    # Supprimer les lignes sans PIB
df_pib = df_pib.dropna(subset=["PIB_Habitant"])

# Population

    # Fusionner les colonnes années en une seule colonne 'Année'
df_pop = df_pop.melt(
    id_vars=["Country Name", "ISO"],
    var_name="Annee",
    value_name="Population"
)

    # Convertir l'année en nombre
df_pop["Annee"] = pd.to_numeric(df_pop["Annee"], errors="coerce")

    # Supprimer les lignes sans PIB
df_pop = df_pop.dropna(subset=["Population"])

# Taux d'urbanisation

    # Fusionner les colonnes années en une seule colonne 'Année'
df_urbanisation = df_urbanisation.melt(
    id_vars=["REF_AREA_LABEL", "ISO"],
    var_name="Annee",
    value_name="Taux_urbanisation"
)

    # Convertir l'année en nombre
df_urbanisation["Annee"] = pd.to_numeric(df_urbanisation["Annee"], errors="coerce")

    # Supprimer les lignes sans PIB
df_urbanisation = df_urbanisation.dropna(subset=["Taux_urbanisation"])

# IDH

    # Mise en forme

df_IDH.rename(columns={'Human Development Index':'hdi'}, inplace=True)
df_IDH["Year"] = df_IDH["Year"].astype(str)

    # Création d'une colonne qui catégorise l'IDH selon les critères de l'ONU

bins = [0, 0.55, 0.70, 0.80, 1.0]
labels = ["Très faible", "Moyen", "Élevé", "Très élevé"]
df["classe_IDH"] = pd.cut(df["hdi"], bins=bins, labels=labels, right=False)

    # Création de la clé de jointure
df_IDH["Key"] = df_IDH["ISO"] + df_IDH["Year"]

# Pays en guerre

    # Mise en forme
df_conflit["Type de conflit"] = df_conflit['Type de conflit'].str.lower()

    # Intégration des conflits uniquement sur 2023
df_conflit['Année']=2023

    # création de la clé de jointure
df_conflit["key_2"] = df_conflit["Année"].astype(str) + "_" + df_conflit["Pays / Territoires"].astype(str)

"""## *Fusion avec la base de données principale*"""

### jointure entre population et taux d'urbanisation sur l'iso code du pays et l'année ###

df_merge=pd.merge(df_pop,df_urbanisation, on=["ISO","Annee"], how="left")

### Jointure avec le PIB sur l'iso code du pays et l'année ###

df_merge2=pd.merge(df_merge,df_pib, on=["ISO","Annee"], how="left")

# Création d'une clé de jointure sur la nouvelle table

df_merge2["Key"] = df_merge2["ISO"] + df_merge2["Annee"].astype(str)

# Création de la clé de jointure sur la base de données principale

df["Key"] = df["iso"] + df["start_year"].astype(str)

### Jointure entre la base principale et la nouvelle table ###

df=pd.merge(df,df_merge2, on=["Key"], how="left")

# suppression des colonnes inutiles

df=df.drop(columns={"Country Name_y","REF_AREA_LABEL","Annee","Country Name_x", "ISO"})

# Création de la clé de jointure sur la table IDH

df_IDH["Key"] = df_IDH["ISO"] + df_IDH["Year"]

### Jointure de la base principale avec l'IDH ###

df=pd.merge(df,df_IDH[['Key','hdi']], on=["Key"], how="left")

# Création de la seconde clé sur la base principale

df["key_2"] = df["start_year"].astype(str) + "_" + df["pays"].astype(str)

### Jointure de la base principale avec la liste des pays en guerre ###
df = pd.merge(left=df, right=df_conflit, on='key_2', how='left')

# Suppression de la seconde clé
df = df.drop(columns='key_2')

"""# **Export vers Google sheet**"""

!pip install --upgrade gspread gspread_dataframe

# autorisation
from google.colab import auth
auth.authenticate_user()

import gspread
from google.auth import default
creds, _ = default()
gc = gspread.authorize(creds)

sh = gc.open_by_url("https://docs.google.com/spreadsheets/d/18J19ZKC8DBW5e9svjGgfdHFJaSWMvfQiJmErxYprL7U/edit?gid=1303832990#gid=1303832990")
worksheet = sh.worksheet("disaster_colab")

from gspread_dataframe import set_with_dataframe
set_with_dataframe(worksheet, df)

"""# ** Annexes ** #"""

# API risque pays
import requests

url = f"https://api.tugo.com/v1/travelsafe/countries/TUN"

headers = {
        "accept": "application/json",
        "Authorization": "Bearer qrn52hfkz74kd6e58q54e8e4"
    }

response = requests.get(url, headers=headers)